ğŸ§  AI Interview Coach

An intelligent desktop app built with Python + Tkinter + AI models that analyzes your speech, posture, eye contact, and sentiment in real-time or from recorded videos â€” helping you improve your interview performance.

ğŸš€ Features

âœ… ğŸ™ Live Interview Mode â€“ Record via webcam + mic with real-time subtitles and live sentiment color feedback (green, red, white).
âœ… ğŸ“‚ Recorded Video Analysis â€“ Upload any pre-recorded interview video to get a complete AI-generated report.
âœ… ğŸ“Š Smart Report Dashboard â€“ Displays:

Posture Score

Eye Contact Score

Speech Sentiment Score

Overall Interview Confidence
âœ… ğŸ§ Posture & Eye Tracking â€“ Uses MediaPipe to analyze body alignment and gaze direction.
âœ… ğŸ’¬ Speech Sentiment Analysis â€“ Powered by Vosk ASR + HuggingFace Transformers to evaluate positivity and clarity in tone.
âœ… ğŸ¨ Beautiful Dynamic UI â€“ Modern Tkinter interface with dark mode, smooth layout, and vivid live feedback colors.

ğŸ› ï¸ Tech Stack
Layer	Technologies Used
Frontend (GUI)	Tkinter, Pillow (PIL), Matplotlib
Speech Processing	Vosk (Offline ASR), SoundDevice
Sentiment Analysis	Transformers (BERT / RoBERTa), Torch
Posture Detection	OpenCV, MediaPipe
Video Handling	MoviePy
Backend Logic	Python 3.12, Threading, JSON
Visualization	Matplotlib (Pie Charts), Tkinter Canvas
Packaging	requirements.txt for reproducible setup
âš™ï¸ Installation
1ï¸âƒ£ Clone the Repository
git clone https://github.com/nihals007/AI-Interview-Coach.git
cd AI-Interview-Coach1

2ï¸âƒ£ Create & Activate a Virtual Environment
python -m venv venv
venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Run the App
python app.py

ğŸ§© Folder Structure
AI-Interview-Coach1/
â”‚
â”œâ”€â”€ app.py                      # Main Tkinter Application
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ posture_model.py        # Body posture and eye-contact analyzer
â”‚   â”œâ”€â”€ speech_model.py         # Speech recording & transcription logic
â”‚   â””â”€â”€ sentiment_model.py      # Text sentiment analyzer (Transformers)
â”‚
â”œâ”€â”€ requirements.txt            # All dependencies
â”œâ”€â”€ snapshot.jpg                # Auto-generated snapshot (from last test)
â”œâ”€â”€ audio.wav                   # Temporary recorded audio file
â””â”€â”€ .gitignore                  # Keeps venv and cache files out of Git

ğŸ’¡ How It Works

Live Mode:

Opens webcam & mic, records video and audio.

Uses Vosk for real-time speech recognition.

Runs live sentiment detection â†’ subtitle colors:
ğŸŸ¢ Positive | âšª Neutral | ğŸ”´ Negative

Analyzes facial alignment (eye contact) and posture with MediaPipe.

On stop â†’ generates detailed report with pie chart + transcript.

Recorded Video Mode:

Upload any .mp4 / .avi / .mov file.

Extracts audio, runs transcription + sentiment + posture frame sampling.

Creates a full AI feedback report with realistic scoring.

ğŸ“Š Example Report
Metric	Score	Description
ğŸ§ Posture	82%	Slight slouch but stable presence
ğŸ‘€ Eye Contact	88%	Mostly maintained eye contact
ğŸ’¬ Speech	79%	Positive and articulate tone
ğŸ¯ Overall	83%	Great confidence! Minor posture improvement needed
ğŸ“¸ Screenshots

(Add your screenshots here once you present)

ğŸŸ¢ Live Mode with subtitles

ğŸ“‚ Recorded video upload screen

ğŸ“Š AI-generated report window

ğŸ‘©â€ğŸ’» Contributors

Team Interview Architects

AI Models by Open Source Communities (HuggingFace, Vosk, MediaPipe)

ğŸ§° Future Enhancements

Browser-based version using Flask + React

Emotion recognition via facial analysis

Voice modulation + clarity score

Resume-based question simulation
